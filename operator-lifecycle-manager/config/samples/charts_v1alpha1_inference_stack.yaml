apiVersion: doublewordai.co/v1alpha1
kind: InferenceStack
metadata:
  name: inference-stack-sample
spec:
  # Default values copied from <project_dir>/helm-charts/inference-stack/values.yaml
  applicationTemplate:
    affinity: {}
    env: null
    image:
      pullPolicy: IfNotPresent
      repository: tytn/takeoff-pro
      tag: 0.22.0-rc15-gpu
    ingress:
      annotations: {}
      className: ""
      enabled: false
      hosts:
      - host: chart-example.local
        paths:
        - path: /
          pathType: ImplementationSpecific
      tls: []
    livenessProbe: null
    nodeSelector: {}
    podAnnotations: {}
    podLabels: {}
    podSecurityContext: {}
    ports:
    - containerPort: 3000
      name: inference
      protocol: TCP
    - containerPort: 3001
      name: management
      protocol: TCP
    - containerPort: 3003
      name: openai
      protocol: TCP
    - containerPort: 3005
      name: internal
      protocol: TCP
    readerConfig:
      consumerGroup: primary
      device: cpu
      modelName: TitanML/dummy_model
    readinessProbe: null
    replicaCount: 1
    resources: {}
    scaling:
      annotations: null
      enabled: false
      spec:
        advanced:
          horizontalPodAutoscalerConfig:
            behavior:
              scaleDown:
                policies:
                - periodSeconds: 300
                  type: Pods
                  value: 1
                stabilizationWindowSeconds: 300
              scaleUp:
                policies:
                - periodSeconds: 300
                  type: Pods
                  value: 1
                stabilizationWindowSeconds: 300
          restoreToOriginalReplicaCount: false
        cooldownPeriod: 300
        idleReplicaCount: 0
        initialCooldownPeriod: 0
        maxReplicaCount: 100
        minReplicaCount: 1
        pollingInterval: 30
        triggers:
        - metadata:
            name: queue_size_trigger
            query: queue_time{job~=".*-controller", quantile="1", consumer_group="primary"}
            serverAddress: http://takeoff-kube-promethe-prometheus:9090/
            threshold: 1
          type: prometheus
        - metadata:
            activationThreshold: 0
            name: scaling_to_zero_trigger
            query: rate(http_pre_handler_requests_total{job~=".*-controller", path=~".*primary.*"}[1m])
            serverAddress: http://takeoff-kube-promethe-prometheus:9090/
            threshold: 1000000
          type: prometheus
    securityContext: {}
    service:
      ports:
      - name: http
        port: 80
        protocol: TCP
        targetPort: openai
      - name: management
        port: 3001
        protocol: TCP
      - name: inference
        port: 3000
        protocol: TCP
      - name: internal
        port: 3005
        protocol: TCP
      type: ClusterIP
    tolerations: []
    volumeMounts: []
    volumes: []
  applications: {}
  gateway:
    affinity: {}
    config: null
    env: null
    exportPrometheusMetrics: false
    image:
      pullPolicy: IfNotPresent
      repository: tytn/takeoff-pro
      tag: 0.22.0-rc15-cpu
    ingress:
      annotations: {}
      className: ""
      enabled: false
      hosts:
      - host: chart-example.local
        paths:
        - path: /
          pathType: ImplementationSpecific
      tls: []
    livenessProbe: {}
    nodeSelector: {}
    podAnnotations: {}
    podLabels: {}
    podSecurityContext: {}
    ports:
    - containerPort: 3000
      name: inference
      protocol: TCP
    - containerPort: 3001
      name: management
      protocol: TCP
    - containerPort: 3003
      name: openai
      protocol: TCP
    - containerPort: 3005
      name: internal
      protocol: TCP
    readinessProbe: {}
    replicaCount: 1
    resources: {}
    securityContext: {}
    service:
      ports:
      - name: http
        port: 80
        protocol: TCP
        targetPort: openai
      - name: management
        port: 3001
        protocol: TCP
      - name: inference
        port: 3000
        protocol: TCP
      - name: internal
        port: 3005
        protocol: TCP
      type: ClusterIP
    tolerations: []
    volumeMounts: []
    volumes: []
  fullnameOverride: ""
  imagePullSecrets: []
  nameOverride: ""
  serviceAccount:
    annotations: {}
    automount: true
    create: true
    name: ""
  
  
