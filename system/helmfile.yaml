environments: 
  default: 
    values: 
      - values.yaml.gotmpl
  microk8s:
    values: 
      - values.microk8s.yaml
  gke:
    values: 
      - values.gke.yaml
      
---
repositories:
- name: keda
  url: "https://kedacore.github.io/charts"
- name: takeoff
  url: "https://titanml.github.io/helm-charts"
- name: argo-cd
  url: "https://argoproj.github.io/argo-helm"
- name: nvidia
  url: "https://helm.ngc.nvidia.com/nvidia"

releases:
# # KEDA is a Kubernetes-based Event Driven Autoscaler. With KEDA, you can drive
# # the scaling of any container in Kubernetes based on the number of events
# # needing to be processed. KEDA is used to drive autoscaling of the inference
# # stack.
- name: keda
  chart: keda/keda
  version: 2.15.1
  namespace: keda

# The takeoff monitoring stack. Installs prometheus + grafana, and dashboards
- name: monitoring
  chart: takeoff/monitoring
  version: 0.1.0
  namespace: monitoring
  set:
  - name: kube-prometheus-stack.prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.metadata.namespace
    value: monitoring
  - name: kube-prometheus-stack.prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName
    value: {{ .Values.monitoring.prometheusStorageClassName }}

# Install argocd: a GitOps continuous delivery tool for Kubernetes
- name: argo-cd
  chart: argo-cd/argo-cd
  version: 7.0.0
  installed: {{ .Values.argocd.enabled }}
  namespace: argocd
  set:
  - name: namespaceOverride
    value: argocd

# https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/google-gke.html#using-nvidia-driver-manager
- name: gpu-operator-dependencies
  chart: ./charts/gpu-operator-dependencies/
  installed: {{ .Values.gpuOperator.enabled }}
  namespace: gpu-operator

- name: gpu-operator
  needs: 
    - gpu-operator-dependencies
  chart: nvidia/gpu-operator
  installed: {{ .Values.gpuOperator.enabled }}
  namespace: gpu-operator
  version: "v25.3.0"
  labels: 
    name: gpu-operator
  values: 
    {{- .Values.gpuOperator.values | toYaml | nindent 4 }}

